{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN2k6MG5T8rQ5/a+GE4svIF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "## importing required libraries\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pXiF1RCCQFjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install pandas numpy pytube pydub openai-whisper --quiet langchain_experimental langchain_openai"
      ],
      "metadata": {
        "id": "mBeCD42rBjjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Video and Extract Audio"
      ],
      "metadata": {
        "id": "0DDPsKJ-Qyu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytube import YouTube"
      ],
      "metadata": {
        "id": "DGtDXjbpQgDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "link= YouTube(\"https://www.youtube.com/watch?v=Sby1uJ_NFIY\")"
      ],
      "metadata": {
        "id": "TcObgKGiQgAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video= link.streams.get_highest_resolution()"
      ],
      "metadata": {
        "id": "zWXlMxyUQf7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video.download('video')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_pJVSI4nSSe-",
        "outputId": "bda0f1d7-c8e0-4e7c-e978-7b81fbafaa26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/video/Sarvam AI Wants To Leverage AI In Health & Education Says Co Founder Vivek Raghavan With OpenHathi.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio=link.streams.get_audio_only()"
      ],
      "metadata": {
        "id": "UdtRZ8opQf4b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio.download('audio')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qALsPBcdSV0x",
        "outputId": "445453d4-a53b-4231-fda8-5ae58271e34f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/audio/Sarvam AI Wants To Leverage AI In Health & Education Says Co Founder Vivek Raghavan With OpenHathi.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcription of Audio"
      ],
      "metadata": {
        "id": "t6ha5_BkS207"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explanation of the Chosen Model: Whisper\n",
        "\n",
        "**Whisper** is an advanced speech recognition model developed by OpenAI, known for its high accuracy and versatility. Here's a detailed explanation of why Whisper is an excellent choice for transcription, along with techniques used to enhance the quality of the transcription:\n",
        "\n",
        "#### Why Whisper?\n",
        "\n",
        "1. **High Accuracy**:\n",
        "   - Whisper is trained on a large and diverse dataset, which helps it achieve high accuracy in various languages and accents. It leverages a transformer-based architecture, which is known for its effectiveness in handling sequential data like audio.\n",
        "\n",
        "2. **Robustness to Noise**:\n",
        "   - Whisper is designed to perform well even in noisy environments, making it suitable for real-world applications where audio quality can be variable.\n",
        "\n",
        "3. **Multilingual Support**:\n",
        "   - Whisper supports transcription in multiple languages, making it a versatile tool for global applications.\n",
        "\n",
        "4. **Automatic Punctuation and Formatting**:\n",
        "   - The model is capable of adding punctuation and formatting to the transcriptions, which significantly improves readability and usability.\n",
        "\n",
        "#### Techniques to Enhance the Quality of Transcription\n",
        "\n",
        "While Whisper is inherently powerful, several techniques can further enhance the transcription quality:\n",
        "\n",
        "1. **Preprocessing the Audio**:\n",
        "   - **Noise Reduction**: Applying noise reduction algorithms to the audio before transcription can improve accuracy. This can be achieved using libraries like `pydub` or `noisereduce`.\n",
        "   - **Normalization**: Normalizing the audio volume ensures consistent input levels, which can help the model perform better.\n",
        "\n",
        "2. **Chunking the Audio**:\n",
        "   - **Short Segments**: Splitting the audio into shorter segments (e.g., 15 seconds) can help manage long audio files more effectively and reduce errors due to model limitations on input length.\n",
        "   - **Semantic Segmentation**: Using voice activity detection (VAD) to segment the audio based on speech presence ensures that each chunk contains meaningful speech, improving the model's focus and accuracy.\n",
        "\n",
        "3. **Language Model Integration**:\n",
        "   - **Custom Language Models**: Integrating domain-specific language models can help the transcription system better handle jargon, proper names, and context-specific terms. This involves fine-tuning Whisper or using external language models to post-process the transcription.\n",
        "\n",
        "4. **Post-processing the Transcription**:\n",
        "   - **Spell Check and Grammar Correction**: Using tools like `nltk` or `spaCy` for post-processing can help correct spelling and grammar errors in the transcription.\n",
        "   - **Manual Review**: For critical applications, manual review and correction of the transcriptions can ensure the highest accuracy.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AMoWhTXc852Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import whisper\n",
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "result = model.transcribe(\"/content/audio/Sarvam AI Wants To Leverage AI In Health & Education Says Co Founder Vivek Raghavan With OpenHathi.mp4\", language=\"en\", task=\"transcribe\")\n",
        "\n",
        "with open(\"transcript.txt\", \"w\") as f:\n",
        "    f.write(result[\"text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzfz65m4KQg0",
        "outputId": "d4752a12-e538-4d96-92c5-05d2cabb23cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 63.5MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Time-Align Transcript with Audio"
      ],
      "metadata": {
        "id": "5M7Nj6_awYkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Y0vqbDxexh8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import pandas as pd\n",
        "# Load the model\n",
        "model = whisper.load_model(\"base\")  # You can choose a different model\n",
        "# Transcribe an audio file\n",
        "result = model.transcribe(\"/content/audio/Sarvam AI Wants To Leverage AI In Health & Education Says Co Founder Vivek Raghavan With OpenHathi.mp4\", language=\"en\", task=\"transcribe\")\n",
        "# Print the text with timestamps\n",
        "\n",
        "segments=[]\n",
        "# Populate the DataFrame with segments\n",
        "for  segment in result['segments']:\n",
        "    start = segment['start']\n",
        "    end = segment['end']\n",
        "    text = segment['text']\n",
        "    segments.append({'start': start, 'end': end, 'text': text})\n",
        "\n",
        "df=pd.DataFrame(segments)\n",
        "df.to_csv('transcription_segments.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rq_axcPeSrrY",
        "outputId": "d0134f4a-b84e-4826-aa53-561afab44da4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Chunking of Data"
      ],
      "metadata": {
        "id": "WFiKawOkxjX8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### using open-ai langchain"
      ],
      "metadata": {
        "id": "GU1TTHiRuwGv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet langchain_experimental langchain_openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h875GgoCWCyQ",
        "outputId": "b32924fd-4048-43d3-c995-100eac72f376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/199.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.9/307.9 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m973.7/973.7 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.2/121.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is a long document we can split up.\n",
        "with open(\"/content/transcript.txt\") as f:\n",
        "    transcript = f.read()"
      ],
      "metadata": {
        "id": "IEMlAERnWIGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create text splitter\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "VckgMxj-WGaL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bFT37UY0fU_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
      ],
      "metadata": {
        "id": "dENOb1WcfWeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = SemanticChunker(\n",
        "    OpenAIEmbeddings(), breakpoint_threshold_type=\"percentile\"\n",
        ")"
      ],
      "metadata": {
        "id": "iuL28bysuM6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = text_splitter.create_documents([transcript])"
      ],
      "metadata": {
        "id": "GD_E-Z7CuM22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('semantic_chunks.pkl', 'wb') as file:\n",
        "    pickle.dump(docs, file)"
      ],
      "metadata": {
        "id": "iMuKkki8x53F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### using Naive approach"
      ],
      "metadata": {
        "id": "ovB8D_fZvDJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import whisper\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def chunk_audio_text( max_chunk_length=15):\n",
        "    chunks = []\n",
        "    current_chunk = {\"start\": 0, \"end\": 0, \"text\": \"\"}\n",
        "    current_length = 0\n",
        "    chunk_id = 1\n",
        "    # Load the model\n",
        "    model = whisper.load_model(\"base\")  # You can choose a different model\n",
        "    # Transcribe an audio file\n",
        "    transcription_result = model.transcribe(\"/content/audio/Sarvam AI Wants To Leverage AI In Health & Education Says Co Founder Vivek Raghavan With OpenHathi.mp4\", language=\"en\", task=\"transcribe\")\n",
        "    # Print the text with timestamps\n",
        "    for segment in transcription_result['segments']:\n",
        "        segment_start = segment['start']\n",
        "        segment_end = segment['end']\n",
        "        text = segment['text']\n",
        "\n",
        "        # Split the text into sentences for better semantic chunks\n",
        "        sentences = sent_tokenize(text)\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence_length = (segment_end - segment_start) * len(sentence) / len(text)\n",
        "\n",
        "            if current_length + sentence_length > max_chunk_length:\n",
        "                chunks.append({\n",
        "                    \"chunk_id\": chunk_id,\n",
        "                    \"chunk_length\": current_chunk[\"end\"] - current_chunk[\"start\"],\n",
        "                    \"text\": current_chunk[\"text\"].strip(),\n",
        "                    \"start_time\": current_chunk[\"start\"],\n",
        "                    \"end_time\": current_chunk[\"end\"]\n",
        "                })\n",
        "                chunk_id += 1\n",
        "                current_chunk = {\"start\": segment_start, \"end\": segment_start + sentence_length, \"text\": sentence}\n",
        "                current_length = sentence_length\n",
        "            else:\n",
        "                current_chunk[\"end\"] = segment_start + sentence_length\n",
        "                current_chunk[\"text\"] += \" \" + sentence\n",
        "                current_length += sentence_length\n",
        "\n",
        "    if current_chunk[\"text\"]:\n",
        "        chunks.append({\n",
        "            \"chunk_id\": chunk_id,\n",
        "            \"chunk_length\": current_chunk[\"end\"] - current_chunk[\"start\"],\n",
        "            \"text\": current_chunk[\"text\"].strip(),\n",
        "            \"start_time\": current_chunk[\"start\"],\n",
        "            \"end_time\": current_chunk[\"end\"]\n",
        "        })\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Example usage\n",
        "audio_text_chunks = chunk_audio_text( )\n",
        "\n",
        "# Print the formatted output\n",
        "for chunk in audio_text_chunks:\n",
        "    print(chunk)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbBRUpAFvHeN",
        "outputId": "de9038af-3748-4b58-d8f2-f561d6457739"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "100%|████████████████████████████████████████| 139M/139M [00:00<00:00, 164MiB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'chunk_id': 1, 'chunk_length': 19.382857142857144, 'text': \"Congratulations to you Mr. Raghavan for that. Thank you so much for joining us.  Over to you.  Hi everybody. How are you?  Okay I am not hearing this at all. It's like a post lunch energy downer or something.  Let's hear it. Are you guys awake?\", 'start_time': 0, 'end_time': 19.382857142857144}\n",
            "{'chunk_id': 2, 'chunk_length': 16.16, 'text': \"All right you better be because we have a superstar guest here.  You heard the 41 million dollars and I didn't hear honestly anything she said after that.  So we're going to ask for about 40 million dollars from him by the end of this conversation.\", 'start_time': 21.84, 'end_time': 38.0}\n",
            "{'chunk_id': 3, 'chunk_length': 16.479999999999997, 'text': \"But let's get started. I want to introduce Vivek and Pratius, she's co-founder who's not here.  We wanted to start with a playing a video of what OpenHathe does. I encourage all of you to go  to the website, www.severalm.ai and check it out.\", 'start_time': 39.68, 'end_time': 56.16}\n",
            "{'chunk_id': 4, 'chunk_length': 15.687272727272735, 'text': \"But let me start by introducing Vivek. Vivek is a  dear friend and he is very, very modest. One of the most modest guys that I know. But his personal  journey Vivek, you've got a PhD from Carnegie Mellon.\", 'start_time': 53.12, 'end_time': 68.80727272727273}\n",
            "{'chunk_id': 5, 'chunk_length': 16.576000000000008, 'text': \"You've sat in and sold the company to Magma.  Vivek and I moved back to India from both in the valley on the same day actually. And you've been  in India for the last 16 years. And what most people don't know is your journey at Adhar.\", 'start_time': 65.36, 'end_time': 81.936}\n",
            "{'chunk_id': 6, 'chunk_length': 10.057872340425533, 'text': 'He spent 13 years selflessly at Adhar. Nobody would have heard of him. But he was a pioneering  technology visionary behind Adhar which we all take for granted today. So please give it out.', 'start_time': 85.12, 'end_time': 95.17787234042554}\n",
            "{'chunk_id': 7, 'chunk_length': 12.796701030927835, 'text': \"Honestly when people, when I think of selfless service, truly selfless service, I always think of  Vivek. And since then he also was at AI for Bharat which we're going to touch on where he met Pratiyusha's  other co-founder.\", 'start_time': 102.32000000000001, 'end_time': 115.11670103092784}\n",
            "{'chunk_id': 8, 'chunk_length': 15.49052631578948, 'text': \"Pratiyusha had a PhD from ETH at Zurich. He was in the IBM research. He was at  Microsoft Research playing a key role and a faculty at IIT Madras and at AI for Bharat. So that's  a little brief introduction about them.\", 'start_time': 113.84, 'end_time': 129.33052631578948}\n",
            "{'chunk_id': 9, 'chunk_length': 14.8408163265306, 'text': \"These guys are modest, modest engineers. So they don't  do their own hon. So forgive me for tooting their hon in this case. But let's jump right in  about the money. Funding. 41 million bucks man. That's a lot of money.\", 'start_time': 127.04, 'end_time': 141.8808163265306}\n",
            "{'chunk_id': 10, 'chunk_length': 15.007826086956527, 'text': \"Every entrepreneur here is  saying what the hell did guys do? What did the investors see to write such a big check?  No, I think it's a trend of what's going on in India. I think that for the very first time,\", 'start_time': 140.48, 'end_time': 155.48782608695652}\n",
            "{'chunk_id': 11, 'chunk_length': 14.7895652173913, 'text': \"I think the investors have looked at, let's try and build something deep-tech out of the country.  And let's try to figure out how to build something as a foundational technology out of the country.  And that's really what's really exciting.\", 'start_time': 160.4, 'end_time': 175.1895652173913}\n",
            "{'chunk_id': 12, 'chunk_length': 19.822439024390235, 'text': \"And I think that about as Balav is mentioning for  the past 15 years, I've been working in both digital public infrastructure and kind of  non-profit kind of things.\", 'start_time': 170.88, 'end_time': 190.70243902439023}\n",
            "{'chunk_id': 13, 'chunk_length': 15.937777777777768, 'text': 'But when this whole thing of generative AI came about,  we said, okay, how can I actually make a difference in this space? And I said, maybe this is the  opportunity to actually come out and really build something.', 'start_time': 189.28, 'end_time': 205.21777777777777}\n",
            "{'chunk_id': 14, 'chunk_length': 14.975999999999999, 'text': \"And the only way that we realize that  you can do it is actually in the private sector. And I think that's the, and then when we went out  there and we said we want to build something, which is a continuation. And fundamentally,\", 'start_time': 200.88, 'end_time': 215.856}\n",
            "{'chunk_id': 15, 'chunk_length': 7.06608695652173, 'text': \"the question is the reason of what we want to do at Server May I is we want to basically make  generative AI available and accessible to the people in the country. And that's the intent.\", 'start_time': 219.12, 'end_time': 226.18608695652173}\n",
            "{'chunk_id': 16, 'chunk_length': 11.506666666666689, 'text': \"And when we said that we want to do this, there was a resonance in the investment community.  And I think it's a responsibility to really to show that something like this can be built out of  India.\", 'start_time': 231.35999999999999, 'end_time': 242.86666666666667}\n",
            "{'chunk_id': 17, 'chunk_length': 7.281599999999997, 'text': \"So we see that as as as as confidence and a responsibility. And I also hope it's a trend  that that you know that there are many more people like like us who are backed. Because if you look\", 'start_time': 242.4, 'end_time': 249.6816}\n",
            "{'chunk_id': 18, 'chunk_length': 13.4909090909091, 'text': \"at it, maybe it's a large number in a you know in the Indian context, but in the global context,  I think there is just there should be many, many more entrepreneurs who are back to do things in  India. I'm going to come back to the many more entrepreneurs.\", 'start_time': 253.44, 'end_time': 266.9309090909091}\n",
            "{'chunk_id': 19, 'chunk_length': 16.480000000000018, 'text': \"I'm obviously going to ask you about  Bhavish's Krutram. So we're going to come back to that question. But again, 41 million dollars.  I mean, all of what you said, you know, two million dollars, you know, that's a good amount of money\", 'start_time': 264.4, 'end_time': 280.88}\n",
            "{'chunk_id': 20, 'chunk_length': 16.18122448979591, 'text': \"for a startup which you know, which has not yet built anything. What are you going to do with all this money?  I can have a perfect solution for the problem. I think in the last week I've got lots of calls,  lots of lots of people telling me how I can do.\", 'start_time': 280.88, 'end_time': 297.0612244897959}\n",
            "{'chunk_id': 21, 'chunk_length': 13.882947368421071, 'text': \"No, but I know you first, okay? I'll be landed in  the country the same day. I'm in the front of the queue. No, but but but honestly, I think the key  thing in this is is to putting together an amazing team. And we actually have an amazing team,\", 'start_time': 294.24, 'end_time': 308.1229473684211}\n",
            "{'chunk_id': 22, 'chunk_length': 14.057142857142878, 'text': 'but we believe that it is talent that will drive this kind of thing. And so it is it is to get  get key talent. And of course, the other thing is compute. This is extremely expensive compute  wise to actually do these kinds of things.', 'start_time': 311.2, 'end_time': 325.25714285714287}\n",
            "{'chunk_id': 23, 'chunk_length': 14.421818181818196, 'text': \"And I think that those are the two primary things that  that you know, we'd use this for. Okay. I'm computing in my own head as an entrepreneur. Talent,  okay, you have like 2015 people. How much are you paying these guys? But okay, well, you won't touch on that.\", 'start_time': 322.8, 'end_time': 337.2218181818182}\n",
            "{'chunk_id': 24, 'chunk_length': 12.495999999999981, 'text': \"But let's talk about what you guys actually built. What is what is open Hathi? How would you explain  open Hathi to? Many people here who might not have known about it. So I think open Hathi is so  first of all, right?\", 'start_time': 340.48, 'end_time': 352.976}\n",
            "{'chunk_id': 25, 'chunk_length': 13.859199999999987, 'text': 'We come from I personally come from the open source ecosystem and we  we and also from the DPI ecosystem. So we believe that for this to work, we need the ecosystem  to be successful.', 'start_time': 351.52, 'end_time': 365.37919999999997}\n",
            "{'chunk_id': 26, 'chunk_length': 13.06613861386137, 'text': 'And as a result of that, one of the first things we did was, hey, there are these  open source large language models that exist, right? I mean, everybody knows about the Lama family  from Meta. There are others like Mistral.', 'start_time': 364.4, 'end_time': 377.46613861386135}\n",
            "{'chunk_id': 27, 'chunk_length': 15.595428571428556, 'text': 'There are a bunch of open source, you know, large language  models. And then we said, is there any way that take an existing open source model and teach  it language skills, right? I mean, you know, language.', 'start_time': 375.28, 'end_time': 390.87542857142853}\n",
            "{'chunk_id': 28, 'chunk_length': 8.088080808080804, 'text': 'And that is really the, you know, what we decide,  what we said that can we do something like that? And is this a, you know, relatively frugal way of', 'start_time': 389.59999999999997, 'end_time': 397.68808080808077}\n",
            "{'chunk_id': 29, 'chunk_length': 14.301666666666677, 'text': 'actually, you know, making models, you know, work in diverse languages because the truth is still  today. I mean, if you look at the amount of data and knowledge, it is still English dominates  these things.', 'start_time': 400.88, 'end_time': 415.1816666666667}\n",
            "{'chunk_id': 30, 'chunk_length': 13.354893617021276, 'text': 'And I think that how do you actually take and make it understand Indian language,  understand Indian context and all of those things in actually a, in an efficient way? And therefore,  this was an attempt through that.', 'start_time': 414.4, 'end_time': 427.75489361702125}\n",
            "{'chunk_id': 31, 'chunk_length': 16.199569892473107, 'text': \"And it's an open hearty is, you know, is currently based on  the Lama 7 billion model, but we'll be releasing many more models in different languages, different  sizes and things like that as part of this, as part of this series.\", 'start_time': 425.44, 'end_time': 441.6395698924731}\n",
            "{'chunk_id': 32, 'chunk_length': 18.402474226804145, 'text': \"And of course, you know,  we will be building further models on those and doing other things to actually, and we'll also have  end points that people can use. So therefore, it's not, it's definitely, you know, something that people  can can can can use two things.\", 'start_time': 436.96, 'end_time': 455.3624742268041}\n",
            "{'chunk_id': 33, 'chunk_length': 13.555056179775306, 'text': \"And the, that's, that's the essence of what this open hearty is.  So what does it mean to people in the audience here who are either doing their own startups or a  business or or developers? How should they look at OpenAI?\", 'start_time': 453.04, 'end_time': 466.5950561797753}\n",
            "{'chunk_id': 34, 'chunk_length': 16.62530612244899, 'text': \"Oh, sorry, sorry, not OpenAI.  No, yeah, no, no, I think, I think the way you look at it is that we are one of the important things  that we are doing is we're not just building models. We are also going to be building a platform,\", 'start_time': 463.92, 'end_time': 480.545306122449}\n",
            "{'chunk_id': 35, 'chunk_length': 10.319999999999993, 'text': 'a platform for developers where you can actually use a combination of various different kinds of  models, some which are from us, some which are open source, some which may not be open source,', 'start_time': 484.16, 'end_time': 494.48}\n",
            "{'chunk_id': 36, 'chunk_length': 11.953333333333319, 'text': 'and actually to actually pull together and figure out how to deploy, you know,  generative AI applications at scale and understand and evaluate their performance in a efficient  manner.', 'start_time': 494.48, 'end_time': 506.43333333333334}\n",
            "{'chunk_id': 37, 'chunk_length': 14.32000000000005, 'text': \"And that's something that we are planning to do at this and this platform is, you know,  in the next couple of months, we'll be coming out there, it will be available to developers.  But of course, those who want to start with the open source things and hack with that, of course,\", 'start_time': 506.0, 'end_time': 520.32}\n",
            "{'chunk_id': 38, 'chunk_length': 9.223092783505194, 'text': \"please go ahead and do that as well. That's, that's phenomenal. But how does it compare to OpenAI itself  or Google? See, at least the things that we are doing now, right? I mean, one of the things that\", 'start_time': 520.32, 'end_time': 529.5430927835052}\n",
            "{'chunk_id': 39, 'chunk_length': 13.767272727272712, 'text': 'when we thought about building server, we said we want to build a full stack generative AI  company and different people have, and our understanding of full stack is that we need to know how to  train models from scratch.', 'start_time': 534.24, 'end_time': 548.0072727272727}\n",
            "{'chunk_id': 40, 'chunk_length': 15.68666666666661, 'text': 'We need to know how to kind of figure out how to deploy models to solve  real world use cases. And we need to play in the ecosystem to make sure that we can actually deploy  population scale applications, right?', 'start_time': 546.24, 'end_time': 561.9266666666666}\n",
            "{'chunk_id': 41, 'chunk_length': 11.997419354838712, 'text': \"So we were thinking about all of these things. But still,  the models we were talking about are, you know, fairly small models. They are fairly small models,  right? The 7 to maybe up to 70 billion kind of range we're talking about. While these models\", 'start_time': 559.52, 'end_time': 571.5174193548387}\n",
            "{'chunk_id': 42, 'chunk_length': 13.897731958762733, 'text': 'like OpenAI and Google are obviously much bigger models, right? But we want to, but, you know,  we want to understand the techniques and be able to build that muscle to do all of these things,  to make it available to people.', 'start_time': 575.84, 'end_time': 589.7377319587628}\n",
            "{'chunk_id': 43, 'chunk_length': 8.99162790697676, 'text': 'Now, those models are, I mean, as I said, you know, I think that  there is space for all of those things. And I think as even Sridhar was talking about', 'start_time': 587.5999999999999, 'end_time': 596.5916279069767}\n",
            "{'chunk_id': 44, 'chunk_length': 8.285473684210501, 'text': 'earlier in the day, we believe that these smaller models can do very, I mean, many, many kind of  domain specific tasks extremely well, probably even better than the larger models. And that is', 'start_time': 599.68, 'end_time': 607.9654736842105}\n",
            "{'chunk_id': 45, 'chunk_length': 6.986930693069326, 'text': \"really one of the key areas. And so the further value of these kinds of things, right? We are not  aiming in these models to build any AGI, right? That's not our goal here. Our goal is to make things\", 'start_time': 613.2, 'end_time': 620.1869306930694}\n",
            "{'chunk_id': 46, 'chunk_length': 11.737373737373787, 'text': 'that work extremely well for domain specific use cases or increase accessibility through language  and all of those kinds of things. And obviously all of this unique to India. But what is unique about  India?', 'start_time': 624.88, 'end_time': 636.6173737373738}\n",
            "{'chunk_id': 47, 'chunk_length': 10.042448979591882, 'text': 'I mean, like, what is, is anything special in our ecosystem that makes small models focused  with Indian languages better for more suited for our problems? So I think that, I mean, there are', 'start_time': 636.08, 'end_time': 646.1224489795919}\n",
            "{'chunk_id': 48, 'chunk_length': 6.529900990099009, 'text': 'quite a few things that are unique about India, right? The first thing is, I think that we are a  voice first nation. So therefore, I think voice has to be the core to doing things. The other thing,', 'start_time': 650.72, 'end_time': 657.249900990099}\n",
            "{'chunk_id': 49, 'chunk_length': 12.559999999999945, 'text': \"of course, India is extremely, it's a cost-conscious country from a cost perspective. Now there,  I would say that there are lots of interesting use cases where you can use OpenAI and the cost\", 'start_time': 663.04, 'end_time': 675.5999999999999}\n",
            "{'chunk_id': 50, 'chunk_length': 12.432842105263148, 'text': \"structure works that when we're depending on your application. But when you want to scale things  to a massive level and make it work, then you have to figure out how small models work. So that's  something that is also specific to India.\", 'start_time': 675.5999999999999, 'end_time': 688.0328421052631}\n",
            "{'chunk_id': 51, 'chunk_length': 5.945600000000013, 'text': 'The third thing which is specific to India is really  the success that India has had in building all this digital public infrastructure. When you add the', 'start_time': 685.8399999999999, 'end_time': 691.7855999999999}\n",
            "{'chunk_id': 52, 'chunk_length': 15.45702127659581, 'text': \"AI layer on top of it, then you can actually get dramatic, you know, dramatic, I think, multiplicative  combinatorial effects based on doing things like that. That's a phenomenal point. Like, you know,  it's like DPI to the power of AI almost in some ways.\", 'start_time': 696.9599999999999, 'end_time': 712.4170212765957}\n",
            "{'chunk_id': 53, 'chunk_length': 10.72489795918375, 'text': \"And as a part of Adar building Adar, no  better person than you. So in summary, what I'm hearing is small models, specialized with trained\", 'start_time': 709.1999999999999, 'end_time': 719.9248979591837}\n",
            "{'chunk_id': 54, 'chunk_length': 6.640816326530626, 'text': \"with Indic specific language data, suited for Indian problems at a compelling cost point. We'll  be suited for us. We're not solving some world autonomous vehicles or some complex problem. We're\", 'start_time': 721.68, 'end_time': 728.3208163265306}\n",
            "{'chunk_id': 55, 'chunk_length': 14.501333333333378, 'text': 'solving some basic problems specifically focused on voice with multiple languages. That is what you  see as a future. Am I paraphrasing this correctly? No, yeah. So I think that certainly, I mean,  voice and Indian languages are an important part of our strategy.', 'start_time': 732.8, 'end_time': 747.3013333333333}\n",
            "{'chunk_id': 56, 'chunk_length': 16.879999999999995, 'text': \"But we will be building  custom models to solve various other kinds of problems as well. That's not just limited to,  I think, in different domains, working in different domains, making building things based on\", 'start_time': 743.84, 'end_time': 760.72}\n",
            "{'chunk_id': 57, 'chunk_length': 12.02566037735835, 'text': \"unique data that enterprises have and things like that. So that's something that we'll also look at.  Fair enough. So coming back to the elephant in the room, no fun intended with OpenHathi.  What about Bavesh Akirwal and Kruthrim? What does your take on that? No, I think it's great.\", 'start_time': 760.72, 'end_time': 772.7456603773584}\n",
            "{'chunk_id': 58, 'chunk_length': 17.425454545454613, 'text': \"I think it's  absolutely wonderful. The fact that the technology AI is so important that we need multiple people  working on it. The fact that there are other people thinking is actually validates that this is an\", 'start_time': 771.5999999999999, 'end_time': 789.0254545454545}\n",
            "{'chunk_id': 59, 'chunk_length': 10.522886597938282, 'text': \"important problem to be solved. And I think that we need everybody to come together and do that.  So I really welcome that. I think it's great. And I think that there'll be different people will\", 'start_time': 789.8399999999999, 'end_time': 800.3628865979382}\n",
            "{'chunk_id': 60, 'chunk_length': 13.026796116504897, 'text': \"have different takes as to how to solve this kind of problem. And hopefully as a result of that,  the entire ecosystem benefits. One more question and then I want to talk about some of the  predictions that you've boldly made.\", 'start_time': 802.96, 'end_time': 815.9867961165049}\n",
            "{'chunk_id': 61, 'chunk_length': 15.696310679611656, 'text': 'So Vivek, I usually ask people about what do you think the future  will be and everybody usually hedges. I ask Vivek, what do you think is going to happen by December  2024? What do you think sitting in this room one year later we can expect? And you made three bold  predictions.', 'start_time': 814.32, 'end_time': 830.0163106796117}\n",
            "{'chunk_id': 62, 'chunk_length': 15.039999999999964, 'text': 'So I want to talk about that before that I have one last question. What are the top three  applications that you think are relevant for India? You would see the talk about medical.  Well, when any quick summary, what do you think the top three apps are for India for AI?', 'start_time': 829.36, 'end_time': 844.4}\n",
            "{'chunk_id': 63, 'chunk_length': 11.474285714285884, 'text': 'So I mean, I think that as you said things like education and medical are clearly areas where  where I think that things can be leveraged. The whole idea of all these kind of the DPI aspect of', 'start_time': 844.9599999999999, 'end_time': 856.4342857142858}\n",
            "{'chunk_id': 64, 'chunk_length': 9.826086956521635, 'text': \"it is another major application where things can happen. And here I'm talking about country specific  what. And I think the whole idea which we've also talked about was the concept of software.\", 'start_time': 859.5200000000001, 'end_time': 869.3460869565217}\n",
            "{'chunk_id': 65, 'chunk_length': 12.249904761904759, 'text': \"And I think that and clearly we have a very large software industry and how to reimagine those  things in this context is also something that's going to be big. Fair enough. Are you guys ready for  Vivek Raghavan's bold predictions? Yes?\", 'start_time': 869.76, 'end_time': 882.0099047619047}\n",
            "{'chunk_id': 66, 'chunk_length': 17.159603960395998, 'text': \"No, I'm not hearing any. Yes. This is like a big deal. He's like  one of the smartest guys that I know. He wants to make three predictions. You don't want to hear it.  All right. So I asked him, what do you think, you know, year later, what do you think we can expect?\", 'start_time': 881.76, 'end_time': 898.919603960396}\n",
            "{'chunk_id': 67, 'chunk_length': 9.692631578947385, 'text': \"And he came up with three things and usually people give very blind answers when you ask  question like this because they don't want to be caught wrong. Not Vivek. Vivek is bold. So he basically  said three things and I'm going to list out the three things and then he's asking about it. So\", 'start_time': 899.68, 'end_time': 909.3726315789473}\n",
            "{'chunk_id': 68, 'chunk_length': 8.086956521739125, 'text': \"number one, he says, I will prefer to talk to an automated customer service than a real person  because they'll give me a better answer. So that is Vivek Raghavan's prediction number one.\", 'start_time': 913.68, 'end_time': 921.7669565217391}\n",
            "{'chunk_id': 69, 'chunk_length': 13.758297872340563, 'text': \"So number two is that when everybody is talking about a GPU shortage, Vivek predicts that there'll be  a GPU glutton India. He thinks there'll be too much GPU. So if you want a short and media stock,  there's a good time.\", 'start_time': 924.56, 'end_time': 938.3182978723405}\n",
            "{'chunk_id': 70, 'chunk_length': 15.93333333333328, 'text': 'And number three, which was extremely unexpected, he said some companies  will suddenly die. Okay. So Vivek, these are not what I expected. So you want to quickly talk about  each of them.', 'start_time': 936.96, 'end_time': 952.8933333333333}\n",
            "{'chunk_id': 71, 'chunk_length': 5.917692307692278, 'text': \"Why you just came up with these and then we'll throw the open audience questions.  So I don't think I quite said it the way that that ballad is not marketing ideas. But it's interesting.\", 'start_time': 952.24, 'end_time': 958.1576923076923}\n",
            "{'chunk_id': 72, 'chunk_length': 12.678709677419306, 'text': \"But I think the first thing that we said is I think that and I don't think that this is I think  there will come a time when in areas of customer service, etc.\", 'start_time': 963.9200000000001, 'end_time': 976.5987096774194}\n",
            "{'chunk_id': 73, 'chunk_length': 20.319999999999936, 'text': \"When you want to do something  very specific, today when you call when you call some kind of a bot, you actually end up,  you mostly try to disconnect the call or you're extremely upset that you're talking to a bot.\", 'start_time': 970.8000000000001, 'end_time': 991.12}\n",
            "{'chunk_id': 74, 'chunk_length': 14.623157894736778, 'text': \"But I think that there will come a time and I'm predicting it sooner than later that you will  actually get better responses from the bot than what the human representative, that at least the  average human representative that you could talk to could give.\", 'start_time': 991.2, 'end_time': 1005.8231578947368}\n",
            "{'chunk_id': 75, 'chunk_length': 11.691089108910887, 'text': \"And I think that that's just a  I just said that that there will come a time where you know it's not a human you're talking to,  but it's probably more likely to solve your intent than the human person. That's just something that\", 'start_time': 1002.32, 'end_time': 1014.0110891089109}\n",
            "{'chunk_id': 76, 'chunk_length': 14.645656565656395, 'text': \"that I think that could happen. Definitely controversial, but we'll let it go. What about the GPU  glut? No, I don't think that so I think that the fact that there is tremendous shortage right now,\", 'start_time': 1019.84, 'end_time': 1034.4856565656564}\n",
            "{'chunk_id': 77, 'chunk_length': 11.120000000000118, 'text': 'I think that shortage will ease because that is how the cycles of things go, right? When when  you know I think the fact that there was such a severe shortage last year, you know basically', 'start_time': 1035.04, 'end_time': 1046.16}\n",
            "{'chunk_id': 78, 'chunk_length': 10.134117647058929, 'text': 'caused a number of different players to ramp up in various kinds of forms. And I think that that  that will always go in a cycle. But you may we may find out that there are many many more interesting', 'start_time': 1046.16, 'end_time': 1056.294117647059}\n",
            "{'chunk_id': 79, 'chunk_length': 14.079999999999927, 'text': 'problems that people will be able to solve. I still remember you know we were at at at at a at a  genie event in Bangalore and we were talking to people and we said you know how many people', 'start_time': 1058.0800000000002, 'end_time': 1072.16}\n",
            "{'chunk_id': 80, 'chunk_length': 14.011881188118878, 'text': 'have access to you know four a hundred. So this was the question that I asked and nobody in the room  and these are all extremely enthusiastic genie people and nobody had access and I think that thing  is going to change. You will be able to get these kinds of things and people who want to hack and do', 'start_time': 1072.16, 'end_time': 1086.171881188119}\n",
            "{'chunk_id': 81, 'chunk_length': 11.940970873786455, 'text': 'things will have access to these things at in without you know having to write a you know a major check  check. The way is also a semi-conductive guy before he went into other so I would take his predictions', 'start_time': 1087.1200000000001, 'end_time': 1099.0609708737866}\n",
            "{'chunk_id': 82, 'chunk_length': 13.096326530612487, 'text': \"very seriously so I don't know what I want to sell my immediate stock. I would not do that but  that's not what I said. I want to blame you for this. I could go that. But the third one is pretty  strange.\", 'start_time': 1099.52, 'end_time': 1112.6163265306125}\n",
            "{'chunk_id': 83, 'chunk_length': 10.773333333333312, 'text': 'You know companies are born companies die but you said some companies will suddenly die.  What does that mean? No I think see I think the the interesting thing is and I think that if it', 'start_time': 1112.0800000000002, 'end_time': 1122.8533333333335}\n",
            "{'chunk_id': 84, 'chunk_length': 12.720000000000027, 'text': \"comes back to the fundamental nature of AI, AI is a tool right and you have to use that and you  have to use that within your business process right and how AI is being used and so and what's\", 'start_time': 1124.32, 'end_time': 1137.04}\n",
            "{'chunk_id': 85, 'chunk_length': 12.799999999999955, 'text': 'going to happen is that I mean I think this is true with you know when someone said in terms of  you know people they said that the people who leverage AI will be will will be more effective than', 'start_time': 1137.04, 'end_time': 1149.84}\n",
            "{'chunk_id': 86, 'chunk_length': 12.480000000000018, 'text': \"those who don't leverage AI and that will true for organizations also organizations that leverage AI  in fundamentally in their core business processes will be more effective than those who don't\", 'start_time': 1149.84, 'end_time': 1162.32}\n",
            "{'chunk_id': 87, 'chunk_length': 12.0, 'text': \"right and I think that's the thing and you won't know the difference until one day it becomes  too obvious and it will be too late and I think that's the reason why everybody needs to think about\", 'start_time': 1162.32, 'end_time': 1174.32}\n",
            "{'chunk_id': 88, 'chunk_length': 12.320000000000164, 'text': 'what it means for your business because you will everything will be fine everything will be fine  and one day somebody in your either either you are competitive in your space or somebody brand new', 'start_time': 1174.3999999999999, 'end_time': 1186.72}\n",
            "{'chunk_id': 89, 'chunk_length': 12.159999999999854, 'text': \"coming into your space will be reimagining your business process completely and at that stage you  will find that it's you know it's a it's a very big very tall you know mountain to climb and\", 'start_time': 1186.72, 'end_time': 1198.8799999999999}\n",
            "{'chunk_id': 90, 'chunk_length': 10.960000000000036, 'text': \"that's why I think it's important for both people and entities to think about how they will  you know they they will upgrade themselves or they will modify their business processes to add\", 'start_time': 1198.88, 'end_time': 1209.8400000000001}\n",
            "{'chunk_id': 91, 'chunk_length': 14.159999999999854, 'text': \"you know that's a very nuanced answer and everybody everybody here who's running a business  should really think about it because life will be the same and then suddenly suddenly something  will you know then there will be a step change we make a few more questions but I'm sure the audience\", 'start_time': 1209.8400000000001, 'end_time': 1224.0}\n",
            "{'chunk_id': 92, 'chunk_length': 8.080000000000155, 'text': 'has a lot of questions for you so how are we doing on time okay so does okay a lot of questions so', 'start_time': 1224.08, 'end_time': 1232.16}\n",
            "{'chunk_id': 93, 'chunk_length': 16.079999999999927, 'text': \"love to is that a mic that we can pass around thank you my name is Kartik I work for  IT service industry so you're saying that you're working on\", 'start_time': 1232.16, 'end_time': 1248.24}\n",
            "{'chunk_id': 94, 'chunk_length': 8.6400000000001, 'text': \"LLM sorry it's it's a fine tuned LLM on top of Lama my basic question fundamental question is\", 'start_time': 1248.24, 'end_time': 1256.88}\n",
            "{'chunk_id': 95, 'chunk_length': 12.7199999999998, 'text': \"we don't have a foundation and model for India most of the models are basically using English or  those kind of things for example you and Andrew was talking about the tokenizers and things\", 'start_time': 1256.88, 'end_time': 1269.6}\n",
            "{'chunk_id': 96, 'chunk_length': 10.480000000000246, 'text': 'like that so are you working on anything like that or you you want to use mostly the existing  models and run on top of it you ask a good question you ask the cherry question for himself', 'start_time': 1269.6, 'end_time': 1280.0800000000002}\n",
            "{'chunk_id': 97, 'chunk_length': 10.0, 'text': \"well I think the interesting thing is that if you look at and then we have actually a blog  on this on our website I think one of the things that we've been we actually built a\", 'start_time': 1281.2, 'end_time': 1291.2}\n",
            "{'chunk_id': 98, 'chunk_length': 10.720000000000027, 'text': \"customized tokenizer which actually fundamentally changes the cost of some of these generations  in Indian languages and and I think that we are we're not just fine tuning we're actually\", 'start_time': 1291.2, 'end_time': 1301.92}\n",
            "{'chunk_id': 99, 'chunk_length': 11.199999999999818, 'text': \"we are leveraging the existing retaining but we are doing what's known as continual free training  which actually but having said that you know I think that once we have to figure out where is the\", 'start_time': 1302.5600000000002, 'end_time': 1313.76}\n",
            "{'chunk_id': 100, 'chunk_length': 12.6400000000001, 'text': 'data to train an extremely large model from scratch and some of those things are things which will  happen over time but I think that I think that yes I think that we will be doing various kinds of', 'start_time': 1313.76, 'end_time': 1326.4}\n",
            "{'chunk_id': 101, 'chunk_length': 11.534845360824875, 'text': \"things but the interesting thing is that if I want to change the accessibility problem with an  existing open source model how do I do that and that's the problem that we have that we think we  have solved and and it's going to be the heart of this open up these things. It's extremely well\", 'start_time': 1326.4, 'end_time': 1337.934845360825}\n",
            "{'chunk_id': 102, 'chunk_length': 13.759999999999991, 'text': \"explained in the blog even I could understand it so. Hi I'm Prishant I work for a Fintech company  my question is like unlike China we never had a consumer facing application coming out from India\", 'start_time': 1341.2800000000002, 'end_time': 1355.0400000000002}\n",
            "{'chunk_id': 103, 'chunk_length': 15.920000000000073, 'text': 'in Web 1, Web 2, crypto and all why do you think it will be different this time in like  AI because will the BPI and other things will solve the same purpose but the great five', 'start_time': 1355.76, 'end_time': 1371.68}\n",
            "{'chunk_id': 104, 'chunk_length': 8.159999999999854, 'text': 'world did in China or do you think like in because AI is a strategic sector no outside country can', 'start_time': 1371.68, 'end_time': 1379.84}\n",
            "{'chunk_id': 105, 'chunk_length': 10.523711340206091, 'text': 'work in NASA projects maybe for government content will go to them what is at least the  mode here for an Indian company.', 'start_time': 1379.84, 'end_time': 1390.363711340206}\n",
            "{'chunk_id': 106, 'chunk_length': 16.24000000000001, 'text': \"So I don't I think I think the the question is I don't know the  answer to these questions right I mean I and I think that it's difficult to predict but I do\", 'start_time': 1386.8799999999999, 'end_time': 1403.12}\n",
            "{'chunk_id': 107, 'chunk_length': 12.559999999999945, 'text': \"believe and as I'm repeating that the combinatorial effect of being using Genai at a large scale  in addition in along with the DPI work that we've done in India will have people and I think that\", 'start_time': 1403.12, 'end_time': 1415.6799999999998}\n",
            "{'chunk_id': 108, 'chunk_length': 13.600000000000136, 'text': \"in the end it is the intent is that people need to be able to use it and they will vote by things  that are useful for them and if that doesn't happen you're right that I think that we have to\", 'start_time': 1415.6799999999998, 'end_time': 1429.28}\n",
            "{'chunk_id': 109, 'chunk_length': 11.252525252525174, 'text': \"figure out what is the mechanism of delivery of apps right I mean in Bhoj out where do Indians consume  contact that's a question. I'm so sorry but we are out of time they will be outside so he would be\", 'start_time': 1429.28, 'end_time': 1440.5325252525251}\n",
            "{'chunk_id': 110, 'chunk_length': 9.759999999999991, 'text': \"able to answer the question we have time for one last question. Can I just take one last? Yeah thank  you thank you I'm Manish Goodhary I'm from ISBR Business School good that I got a chance to ask\", 'start_time': 1442.32, 'end_time': 1452.08}\n",
            "{'chunk_id': 111, 'chunk_length': 10.720000000000027, 'text': 'you this question during lunchtime they were a few of our educationists whom we were talking about  there was one from school and we are from the MBA institutions we were thinking of these', 'start_time': 1452.08, 'end_time': 1462.8}\n",
            "{'chunk_id': 112, 'chunk_length': 10.160000000000082, 'text': \"present generations how do we get them into what you are doing there is one thing that they have  been regularly that the concentrations that they're working on but artificial intelligence and\", 'start_time': 1462.8, 'end_time': 1472.96}\n",
            "{'chunk_id': 113, 'chunk_length': 10.720000000000027, 'text': 'getting into this getting them into their academics and making them a part of it is very important  including the trainers who train them making them future ready into what you are doing is amazing', 'start_time': 1472.96, 'end_time': 1483.68}\n",
            "{'chunk_id': 114, 'chunk_length': 12.160000000000082, 'text': 'and the speed that which is growing it is calling for a lot of training that needs to be done  can you from your angle through some light on how we could make them future ready how these people', 'start_time': 1483.68, 'end_time': 1495.8400000000001}\n",
            "{'chunk_id': 115, 'chunk_length': 9.542857142856974, 'text': 'who are who are management graduates and from schools who are coming out how do we get into this  part of technology that you spoke about. Oh so this is this is really a challenge because I think', 'start_time': 1495.8400000000001, 'end_time': 1505.3828571428571}\n",
            "{'chunk_id': 116, 'chunk_length': 12.799999999999955, 'text': 'everyone will need to understand at some level what this technology does and I think that we  have to rethink how we get everyone into this and that this kind of education has to be at many', 'start_time': 1508.16, 'end_time': 1520.96}\n",
            "{'chunk_id': 117, 'chunk_length': 11.920000000000073, 'text': \"different levels right there are from a core set of having people who are extremely good at some  and there you don't need as many but then there are basically vast numbers of people who can\", 'start_time': 1520.96, 'end_time': 1532.88}\n",
            "{'chunk_id': 118, 'chunk_length': 12.639999999999873, 'text': \"actually leverage these tools by the way the most important thing about maybe that's part of what  makes an LLM interesting is that how you use it your mileage varies by that and to understand\", 'start_time': 1532.88, 'end_time': 1545.52}\n",
            "{'chunk_id': 119, 'chunk_length': 13.120000000000118, 'text': 'how to actually leverage this in an interesting way is something that we have to widely teach many  many people and because asking the you know things in the right way and having the right kind of', 'start_time': 1545.52, 'end_time': 1558.64}\n",
            "{'chunk_id': 120, 'chunk_length': 13.764507042253399, 'text': \"applications will make a huge difference to how people can leverage these tools. Awesome. Thank you.  Thank you very much Vivek very good luck to Sarvam and good luck to India I think it's going to be  a lot of regular resources and thanks Bala.\", 'start_time': 1558.64, 'end_time': 1572.4045070422535}\n",
            "{'chunk_id': 121, 'chunk_length': 2.460845070422465, 'text': 'Thank you Mr. Raghavan and', 'start_time': 1568.24, 'end_time': 1570.7008450704225}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Saving the list to a file using pickle\n",
        "file_path = 'semantic_chunks.pkl'\n",
        "with open(file_path, 'wb') as file:\n",
        "    pickle.dump(audio_text_chunks, file)\n",
        "\n",
        "print(f\"Semantic chunks saved to {file_path}\")\n"
      ],
      "metadata": {
        "id": "RQ1h1a7pvHTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2As9xAwqvHP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4ABSSCUHvHND"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}